```{r chapter-2-setup, echo = FALSE, message = FALSE, warning = FALSE}
library(PerformanceAnalytics)
library(data.table)
library(tidyverse)
library(hrbrthemes)
library(ggcorrplot)
library(GoodmanKruskal)
library(lindia)
library(finalfit)
library(sigr)
library(papaja)
library(here)
library(kableExtra)
```

# Week 2 – Regression and model validation

```{r load-data, echo = FALSE, message= FALSE}

learning2014 <- fread(here("data/learning2014.csv"))

```

## Introduction


[see @vehkalahti2016]

Surface approach: memorizing without understanding, with a serious lack of personal engagement in the learning process. Intention of getting forward with minimium trouble

Deep approach: intention to maximize understanding with ta true commitment to learning. Strong need to engage in the actual content of the task.
STrategic approad: the ways students organize their studying.

ASSIST: the appproaches and study skills inventory for studets -survey (Tait, Etwishle, MacCune, 1008). Items were measured with a five point Likert skale (1=disagree, 5=agree)

Learning approach, 8 subscales, 4 items each.

1. Deep: seeking meaning, relating ideas, use of evidence
2. surface: lack of purpose, unrelated memorizing, syllabus-boundness
3. stratcgic: organized studying, time management

students achievement was measured by points in the exaams

## Exploratory analysis {#explorative-analysis}


```{r graphical-overview-continous, echo = FALSE}
# Show a graphical overview of the data and show summaries of the variables 
# in the data. Describe and interpret the outputs, 
# commenting on the distributions of the variables 
# and the relationships between them. (0-3 points)

chart.Correlation(learning2014[,-1], histogram=TRUE, pch=19, method="pearson")

```

```{r graphical-overview-gender, echo = FALSE, fig.width=5, fig.height=5}
ggplot(learning2014, aes(gender,attitude)) + 
  geom_violin() + 
  theme_ipsum()
```

```{r graphical-overview-gender-age, echo = FALSE, fig.width=5, fig.height=5}
ggplot(learning2014, aes(gender,age)) + 
  geom_violin() + 
  theme_ipsum()
```


```{r graphical-overview-relationship, echo = FALSE}
ggplot(learning2014, aes(color = gender, x = attitude, y = points, size = stra)) + 
  geom_point() + 
  geom_smooth(method = "lm", fill = NA) +
  scale_size_continuous(range = c(0.05,2)) +
  theme_bw()
```

## Regression analysis

In building linear regression models, it is desirable to have high correlations between the prediction covariates and the response variable, but small correlations between the different prediction covariates. Large correlations between prediction variables leads to the problem of collinearity in linear regression. Therefore, based on explorative analysis in [Fig 1](#explorative-analysis), two non-correlating variables where chosen an prediction covariates


The standard requirements for linear regression are:

* Dependent variables have a linear relationship to the independent variable X.
* For each value of X, the probability distribution of Y has the same standard deviation σ.
* For any given value of X,
The Y values are independent.
The Y values are roughly normally distributed (i.e., symmetric and unimodal). A little skewness is ok if the sample size is large.

### Initial model

```{r initial-model-instruction, echo=FALSE, eval=FALSE}
# Choose three variables as explanatory variables and 
# fit a regression model where exam points is the target (dependent) variable.
```


```{r fit-attitude_stra_surf}
model_attitude_stra_surf <- lm(
  data = learning2014, 
  formula = points ~ attitude + stra + surf )

```

```{r model_attitude_stra_surf_summary, echo = FALSE}

# Show a summary of the fitted model and comment and interpret the results. 
# Explain and interpret the statistical test related to the model parameters.

summary_colnames <- c(
  "Predictor",
  "Estimate",
  "Confidence Interval (95%)",
  "t-statistic",
  "p-value")

model_attitude_stra_surf_summary <- apa_print(model_attitude_stra_surf)
knitr::kable(
  model_attitude_stra_surf_summary$table,
  format = "html", col.names = summary_colnames, caption = "Regression summary") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed"))
```

`r render(wrapFTest(model_attitude_stra_surf, pSmallCutoff=0, format="markdown"))` Adjusted <i>R^2^</i> is `r round(summary(model_attitude_stra_surf)$adj.r.squared, 2)`.

### Final model

```{r final-model-instruction, echo = FALSE, eval = FALSE}
# If an explanatory variable in your model does not have 
# a statistically significant relationship with the target variable
# remove the variable from the model and fit the model again without it.
```

```{r fit-attitude_stra}
model_attitude_stra <- lm(
  data = learning2014, 
  formula = points ~ attitude + stra)
```

```{r model_model_attitude_stra_summary, echo = FALSE}
model_attitude_stra_summary <- apa_print(model_attitude_stra)
knitr::kable(
  model_attitude_stra_summary$table,
  format="html", col.names = summary_colnames, caption = "Regression summary") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed"))
```


For the final model `r render(wrapFTest(model_attitude_stra, pSmallCutoff=0, format="markdown"))` Adjusted <i>R^2^</i> is `r round(summary(model_attitude_stra)$adj.r.squared, 2)`.

## Regression diagnostics

```{r instructions, echo = FALSE, eval = FALSE}
# Produce the following diagnostic plots: 
# Residuals vs Fitted values
# Normal QQ-plot
# Residuals vs Leverage. 
# Explain the assumptions of the model and interpret the validity of 
# those assumptions based on the diagnostic plots. (0-3 points)
```




```{r residuals-fitted, echo = FALSE}
gg_resfitted(model_attitude_stra, scale.factor = 1) + theme_bw()
```

Residuals vs Fitted -plot shows if residuals have non-linear patterns. There could be a non-linear relationship between predictor variables and an outcome variable and the pattern could show up in this plot if the model doesn’t capture the non-linear relationship. If you find equally spread residuals around a horizontal line without distinct patterns, that is a good indication you don’t have non-linear relationships. I don’t see any distinctive pattern 


```{r qqplot, echo = FALSE}
gg_qqplot(model_attitude_stra, scale.factor = 1) + theme_bw()

```
Normal Q-Q -plot shows if residuals are normally distributed. Do residuals follow a straight line well or do they deviate severely? It’s good if residuals are lined well on the straight dashed line.



```{r residual-leverage, echo = FALSE}
gg_resleverage(model_attitude_stra, method = "loess", se = FALSE, scale.factor = 1) + theme_bw()

```
This plot helps us to find influential cases (i.e., subjects) if any. Not all outliers are influential in linear regression analysis (whatever outliers mean). Even though data have extreme values, they might not be influential to determine a regression line. 

We watch out for outlying values at the upper right corner or at the lower right corner. Those spots are the places where cases can be influential against a regression line. Look for cases outside of a dashed line, Cook’s distance. When cases are outside of the Cook’s distance (meaning they have high Cook’s distance scores), the cases are influential to the regression results. The regression results will be altered if we exclude those cases.

## Extra - tweaking the model

Just for the sake of curiosiety, let's investige how excluding there outlier cases (35, 56 & 145) has an effect on our regression model. 

```{r fit-attitude_stra-excluded-cases}
learning2014$id <- 1:dim(learning2014)[1]
model_attitude_stra_excluded <- lm(
  data = learning2014 %>% filter(!id %in% c(35, 145, 56)), 
  formula = points ~ attitude + stra)
```

```{r model_model_attitude_stra_excluded-summary, echo = FALSE}
model_attitude_stra_summary_excluded <- apa_print(model_attitude_stra_excluded)
knitr::kable(
  model_attitude_stra_summary_excluded$table,
  format="html", col.names = summary_colnames, caption = "Regression summary") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed"))
```


For the model created using data without cases 35, 145 and 56, the `r render(wrapFTest(model_attitude_stra_excluded, pSmallCutoff=0, format="markdown"))` Adjusted <i>R^2^</i> is `r round(summary(model_attitude_stra_excluded)$adj.r.squared, 2)`.

Effect on the model seems to be pretty huge! Let's see from the data what kind of cases these are so that we could decide if it is prudent to consider them outright outliers.

```{r excluded-cases-table, echo = FALSE}
case_colnames <- c("Gender","Age","Attitude","Deep", "Strategic","Surface","Points")
knitr::kable(
  learning2014 %>% filter(id %in% c(35, 145, 56)) %>% select(-id),
  format="html", col.names = case_colnames, digits = 2, caption = "Outlier cases") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed"))
```
Looking the data, these unfortunate students have scored very low in the test, even though their motivation is strong. It might be that some external cause has affected their test performance as other low-scoring (points <=10) students somewhat differ from these three cases.

```{r low-scoring-students, echo = FALSE}
case_colnames <- c("Gender","Age","Attitude","Deep", "Strategic","Surface","Points")
knitr::kable(
  learning2014 %>% filter(points <= 10) %>% select(-id),
  format="html", col.names = case_colnames, digits = 2, caption = "Low-scoring students") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed"))
```


## References

